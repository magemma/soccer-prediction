{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation\n",
    "\n",
    "This module is mainly responsible for classification and evaluation of the results during which you will see some of the little tricks like grid-search and cross-validation just to make sure the results are valid and awesome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from hyperparameters import params as all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Retrieve the data from the database and split it as input and output of the model. Notice that the fields with the id type are useless now. Other than that, we need to hide the information from the future we're gonna predict from the eyes of our model. Finally, let's pick a portion of the data right here right now and dedicate it to the final testing of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient()\n",
    "db = client['soccerdb']\n",
    "\n",
    "#Load everything into a dataFrame\n",
    "data = pd.DataFrame(list(db.results.find({}, {'_id': 0, 'teamId': 0, 'matchId': 0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which target do you have in mind?\n",
      "\n",
      "0. Didscoreinsecondhalf\n",
      "1. Finalscore\n",
      "2. Iswinner\n",
      "3. Numsecondhalfgoals\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>> 3\n"
     ]
    }
   ],
   "source": [
    "targets = [\n",
    "    {\n",
    "        'name': 'didScoreInSecondHalf',\n",
    "        'type': 'categorical'\n",
    "    }, \n",
    "    {\n",
    "        'name': 'finalScore',\n",
    "        'type': 'numerical'\n",
    "    },\n",
    "    {\n",
    "        'name': 'isWinner',\n",
    "        'type': 'categorical'\n",
    "    },\n",
    "    {\n",
    "        'name': 'numSecondHalfGoals',\n",
    "        'type': 'numerical'\n",
    "    }, \n",
    "]\n",
    "\n",
    "def get_input_output(data, target_col, hidden_info):\n",
    "    y = data[target_col]\n",
    "    X = data.drop(hidden_info + [target_col], axis=1)\n",
    "    return X, y\n",
    "\n",
    "print('Which target do you have in mind?\\n')\n",
    "target_names = [x['name'] for x in targets]\n",
    "for i, itm in enumerate(target_names):\n",
    "    print('{}. {}'.format(str(i), itm.title()))\n",
    "    \n",
    "target_num = int(input('>>>'))\n",
    "desired_target = target_names[target_num]\n",
    "operation_type = targets[target_num]['type']\n",
    "\n",
    "X, y = get_input_output(data, desired_target, target_names)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(algorithm, params, reporting_scores,\n",
    "                       fold=5,):\n",
    "    algorithms = {\n",
    "        'svc': SVC,\n",
    "        'svr': SVR,\n",
    "        'dtc': DecisionTreeClassifier,\n",
    "        'dtr': DecisionTreeRegressor,\n",
    "        'mlp': MLPClassifier,\n",
    "    }\n",
    "    \n",
    "    scores = {\n",
    "        'f1': f1_score,\n",
    "        'accuracy': accuracy_score,\n",
    "    }\n",
    "    \n",
    "    score_fns = []\n",
    "    for score in reporting_scores:\n",
    "        score_fns.append(make_scorer(scores[score]))  # Mapping the str to corresponding function\n",
    "    \n",
    "    results = {'algorithm': algorithm}\n",
    "    clf = GridSearchCV(algorithms[algorithm](), params, cv=fold,\n",
    "                       scoring=score_fns[0])\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    results.update(clf.best_params_)\n",
    "\n",
    "    for i, score in enumerate(reporting_scores):   \n",
    "        results[score] = score_fns[i](clf, X_test, y_test)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['accuracy', 'f1']\n",
    "\n",
    "all_results = []\n",
    "for alg in all_params:\n",
    "    if all_params[alg]['type'] != operation_type:\n",
    "        # Don't do classification when the target is regression and \n",
    "        # vice versa...\n",
    "        continue\n",
    "    \n",
    "    params = all_params[alg]['params']\n",
    "    all_results.append(train_and_validate(alg, params, metrics))\n",
    "    \n",
    "df = pd.DataFrame(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
